{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow, figure\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, UpSampling2D\n",
    "from tensorflow.keras import backend as K\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pixellib\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-object-detection-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad43822",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --ignore-installed --upgrade tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7018ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('Indian Road accidents compilation 2021_480p.mp4')\n",
    "vidcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # creating a folder named data\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data') \n",
    "#if not created then raise error\n",
    "except OSError:\n",
    "    print ('Error: Creating directory of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #frame\n",
    "currentframe = 0\n",
    "while(True):\n",
    "      \n",
    "    # reading from frame\n",
    "    ret,frame = vidcap.read()\n",
    "  \n",
    "    if ret:\n",
    "        # if video is still left continue creating images\n",
    "        name = './data/frame' + str(currentframe) + '.jpg'\n",
    "        print ('Creating...' + name)\n",
    "  \n",
    "        # writing the extracted images\n",
    "        cv2.imwrite(name, frame)\n",
    "  \n",
    "        # increasing counter so that it will\n",
    "        # show how many frames are created\n",
    "        currentframe += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Release all space and windows once done\n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Splitting image data to train, test, and valid data\n",
    "!pip install split-folders tqdm\n",
    "import splitfolders  \n",
    "input_folder= 'data1/'\n",
    "output= 'out_data/'\n",
    "\n",
    "# # To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(input_folder, output, seed=1337, ratio=(.8, .1, .1), group_prefix=None) # default values\n",
    "\n",
    "splitfolders.fixed(input_folder, output, seed=1337, fixed=(100, 100), oversample=False, group_prefix=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4128dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('data1\\data\\\\frame1.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting image data to train, test, and valid data\n",
    "import splitfolders  \n",
    "input_folder= 'df/'\n",
    "output= 'modeldf/'\n",
    "\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.7, .3)`.\n",
    "splitfolders.ratio(input_folder, output, seed=1337, ratio=(.7, .2, .1), group_prefix=None) # default values\n",
    "\n",
    "splitfolders.fixed(input_folder, output, seed=1337, fixed=(100, 100), oversample=False, group_prefix=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('modeldf/train/Accidenthumanerror/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import keras\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2,\n",
    "    shear_range = 0.2,      \n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba20c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory('modeldf/',target_size = (256, 256),\n",
    "                                                    color_mode = \"rgb\")\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "validation_generator = test_datagen.flow_from_directory('modeldf/',target_size = (256, 256),batch_size = 15,color_mode = 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'modeldf/train/',\n",
    "    seed=42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14beeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation =  tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'modeldf/val/',\n",
    "    seed=42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70300ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'modeldf/test',\n",
    "    seed=42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "class_names = training_d.class_names\n",
    "\n",
    "## Configuring dataset for performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "training_ds = training_d.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "testing_ds = testing_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "Cnn = tf.keras.models.Sequential([\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Conv2D(32, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dense(len(class_names),activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "Cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "retVal = Cnn.fit(training_ds, validation_data= validation, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(retVal.history['loss'], label = 'training loss')\n",
    "plt.plot(retVal.history['accuracy'], label = 'training accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(retVal.history['val_loss'], label = 'validation loss')\n",
    "plt.plot(retVal.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets vizualize results on testing data\n",
    "AccuracyVector = []\n",
    "plt.figure(figsize=(30, 30))\n",
    "for images, labels in testing_ds.take(1):\n",
    "    predictions = MyCnn.predict(images)\n",
    "    predlabel = []\n",
    "    prdlbl = []\n",
    "    \n",
    "    for mem in predictions:\n",
    "        predlabel.append(class_names[np.argmax(mem)])\n",
    "        prdlbl.append(np.argmax(mem))\n",
    "    \n",
    "    AccuracyVector = np.array(prdlbl) == labels\n",
    "    for i in range(40):\n",
    "        ax = plt.subplot(10, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title('Pred: '+ predlabel[i]+' actl:'+class_names[labels[i]] )\n",
    "        plt.axis('off')\n",
    "        plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnn.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec313e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(MyCnn, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
